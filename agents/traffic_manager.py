"""
Agente Traffic Manager Pro
Monitora Meta Ads e detecta anomalias com IA
"""

import json
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

class TrafficManagerPro:
    """
    Agente especializado em monitoramento de tr√°fego pago
    Implementa fluxo: Economy ‚Üí Standard ‚Üí Deep (quando necess√°rio)
    """
    
    def __init__(self, router, mock_client=None):
        self.router = router
        self.mock_client = mock_client  # Para modo mock
        self.alert_threshold_roas = 3.0
        self.alert_threshold_ctr = 1.0
        self.performance_history = []
        
        logger.info("üö¶ TrafficManagerPro inicializado")
    
    def analyze(self, date_range: str = "last_7d", use_mock: bool = True, force_scenario: Optional[str] = None) -> Dict:
        """
        Executa an√°lise completa de tr√°fego
        
        Fluxo otimizado:
        1. Coleta dados (economy) - 85% do uso
        2. Analisa performance (standard) - 15% do uso  
        3. Gera alertas se necess√°rio (standard) - apenas se houver issues
        4. Debug complexo se falhar (deep) - <1% do uso
        
        Args:
            date_range: per√≠odo de an√°lise
            use_mock: usar simulador ou API real
            force_scenario: for√ßar cen√°rio espec√≠fico (crisis/boom/normal)
        """
        print(f"\n{'='*70}")
        print("üìä TRAFFIC MANAGER PRO - AN√ÅLISE INICIADA")
        print(f"{'='*70}")
        
        start_time = datetime.now()
        
        try:
            # ETAPA 1: Coleta de dados (Economy - 85%)
            print("\nüì• FASE 1: Coletando dados (economy)...")
            raw_data = self._fetch_data(date_range, use_mock, force_scenario)
            
            # ETAPA 2: An√°lise de performance (Standard - 15%)
            print("\nüß† FASE 2: Analisando performance (standard)...")
            analysis = self._analyze_performance(raw_data)
            
            # ETAPA 3: Alertas (Standard - apenas se necess√°rio)
            alerts = []
            recommendations = []
            
            if analysis['has_issues']:
                print(f"\nüö® FASE 3: Gerando alertas (standard)...")
                alerts = self._generate_alerts(analysis)
                recommendations = analysis.get('recommendations', [])
            else:
                print(f"\n‚úÖ Sem issues detectadas - pulando gera√ß√£o de alertas")
            
            # ETAPA 4: Debug complexo (Deep - <1% - apenas se falhar)
            if analysis.get('parse_error'):
                print(f"\nüîß FASE 4: Debug complexo (deep)...")
                analysis = self._debug_analysis_failure(raw_data)
            
            # Registrar no hist√≥rico
            self._record_performance(analysis, alerts)
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            result = {
                'timestamp': datetime.now().isoformat(),
                'date_range': date_range,
                'execution_time_seconds': execution_time,
                'scenario': raw_data.get('scenario', 'unknown'),
                'raw_data_summary': raw_data['summary'],
                'analysis': analysis,
                'alerts': alerts,
                'recommendations': recommendations,
                'cost_breakdown': self._get_cost_breakdown(),
                'model_usage': self.router.get_stats()['distribution']
            }
            
            print(f"\n‚úÖ An√°lise completa em {execution_time:.1f}s")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise: {e}")
            
            # Fallback: tentar debug com modelo deep
            try:
                print(f"\nüîß Tentando debug com modelo deep...")
                debug_result = self._emergency_debug(str(e))
                return {
                    'timestamp': datetime.now().isoformat(),
                    'date_range': date_range,
                    'error': str(e),
                    'debug_analysis': debug_result,
                    'status': 'failed_with_debug'
                }
            except Exception as debug_error:
                logger.error(f"‚ùå Debug tamb√©m falhou: {debug_error}")
                return {
                    'timestamp': datetime.now().isoformat(),
                    'date_range': date_range,
                    'error': str(e),
                    'status': 'failed'
                }
    
    def _fetch_data(self, date_range: str, use_mock: bool, force_scenario: Optional[str] = None) -> Dict:
        """Coleta dados - Economy mode (85% do uso)"""
        logger.info("üì• Coletando dados do Meta Ads...")
        
        if force_scenario:
            self.mock_client.set_scenario(force_scenario)
        
        if use_mock and self.mock_client:
            # Usar simulador com cen√°rio espec√≠fico
            data = self.mock_client.get_insights(date_range)
            prompt = f"""
            Formate os seguintes dados de campanhas Meta Ads em JSON estruturado e limpo:
            
            Dados brutos: {json.dumps(data, indent=2)}
            
            Retorne APENAS o JSON formatado com esta estrutura:
            {{
                "campaigns": [...],
                "summary": {{...}},
                "trends": {{...}},
                "issues": [...]
            }}
            
            Remova campos desnecess√°rios, mantenha apenas m√©tricas essenciais.
            """
        else:
            # Modo produ√ß√£o - chamada real API
            prompt = f"""
            Busque dados da API Meta Ads para conta {self.mock_client.account_id if self.mock_client else 'production'}.
            Per√≠odo: {date_range}
            
            Retorne JSON com:
            - Campanhas ativas: id, nome, status, objetivo
            - M√©tricas: spend, impressions, clicks, CTR, CPC, conversions, ROAS
            - Resumo agregado
            - Issues detectadas
            
            Formato profissional, dados reais.
            """
        
        response = self.router.call(
            task_type='fetch_meta_data',
            messages=[{"role": "user", "content": prompt.strip()}],
            temperature=0.1,
            max_tokens=2000
        )
        
        # Parse resposta
        content = response.choices[0].message.content.strip()
        
        # Se estiver usando mock, j√° temos os dados estruturados
        if use_mock:
            # Formatar os dados do mock para garantir consist√™ncia
            formatted_data = {
                'campaigns': data['campaigns'],
                'summary': data['summary'],
                'trends': data.get('trends', {}),
                'issues': data.get('issues', []),
                'scenario': data.get('scenario', 'normal'),
                'recommendations': data.get('recommendations', [])
            }
        else:
            try:
                # Tentar parsear JSON da resposta
                formatted_data = json.loads(content)
            except json.JSONDecodeError:
                logger.warning("‚ùå Falha ao parsear JSON, usando dados brutos")
                formatted_data = {
                    'raw_content': content,
                    'parse_error': True,
                    'campaigns': [],
                    'summary': {},
                    'issues': []
                }
        
        logger.info(f"‚úÖ {formatted_data['summary'].get('total_campaigns', 0)} campanhas coletadas")
        return formatted_data
    
    def _analyze_performance(self, data: Dict) -> Dict:
        """Analisa performance - Standard mode (15% do uso)"""
        logger.info("üß† Analisando performance com modelo standard...")
        
        campaigns = data.get('campaigns', [])
        issues = data.get('issues', [])
        trends = data.get('trends', {})
        
        if not campaigns:
            return {
                'has_issues': True,
                'error': 'Nenhuma campanha encontrada',
                'recommendations': ['Verificar conex√£o com Meta Ads']
            }
        
        # Preparar dados para an√°lise
        campaign_data = json.dumps(campaigns[:10], indent=2)  # Limitar para n√£o exceder tokens
        issues_data = json.dumps(issues[:5], indent=2)
        trends_data = json.dumps(trends, indent=2)
        
        prompt = f"""
        Voc√™ √© um especialista s√™nior em performance marketing B2B com foco em e-commerce profissional.
        
        ANALISE ESTES DADOS DE CAMPANHAS META ADS:
        
        CAMPANHAS:
        {campaign_data}
        
        ISSUES DETECTADAS:
        {issues_data}
        
        TEND√äNCIAS:
        {trends_data}
        
        BENCHMARKS B2B REFER√äNCIA:
        - ROAS m√≠nimo aceit√°vel: 3.0x
        - CTR saud√°vel: > 1.0%
        - CPC target: < $1.50
        - CPM m√©dio: $8-15
        
        TAREFAS DE AN√ÅLISE:
        1. Calcule baseline de ROAS e CTR (m√©dia das campanhas boas)
        2. Identifique campanhas underperforming (ROAS < 3.0 ou CTR < 1%)
        3. Calcule risco financeiro: spend total em campanhas ruins
        4. Detecte padr√µes: quedas de CTR, aumento de CPC, etc.
        5. Compare contra benchmarks de e-commerce B2B
        6. Identifique oportunidades de otimiza√ß√£o
        7. Priorize a√ß√µes por impacto vs esfor√ßo
        
        RETORNE JSON estruturado:
        {{
            "has_issues": boolean,
            "baseline_roas": float,
            "baseline_ctr": float,
            "underperforming_campaigns": [
                {{
                    "name": string,
                    "issue": string,
                    "current_value": float,
                    "target": float,
                    "spend_impact": float
                }}
            ],
            "risk_financeiro": float,
            "issues_summary": "descri√ß√£o detalhada dos problemas encontrados",
            "recommendations": [
                "a√ß√£o prioridade alta",
                "a√ß√£o prioridade m√©dia", 
                "a√ß√£o prioridade baixa"
            ],
            "opportunities": [
                "oportunidade de scale",
                "oportunidade de otimiza√ß√£o"
            ]
        }}
        
        Seja espec√≠fico, use n√∫meros reais, seja direto e profissional.
        """
        
        response = self.router.call(
            task_type='analyze_performance',
            messages=[{"role": "user", "content": prompt.strip()}],
            temperature=0.2,
            max_tokens=1500
        )
        
        content = response.choices[0].message.content.strip()
        
        # Extrair JSON da resposta
        try:
            # Tentar parsear direto
            analysis = json.loads(content)
        except json.JSONDecodeError:
            # Extrair JSON de texto com regex
            import re
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                try:
                    analysis = json.loads(json_match.group())
                except:
                    analysis = {
                        'parse_error': True,
                        'raw_response': content[:500],
                        'has_issues': 'CRITICAL' in content.upper() or 'ALERTA' in content.upper()
                    }
            else:
                analysis = {
                    'parse_error': True,
                    'raw_response': content[:200],
                    'has_issues': True
                }
        
        # Garantir campos obrigat√≥rios
        if 'has_issues' not in analysis:
            analysis['has_issues'] = len(analysis.get('underperforming_campaigns', [])) > 0
        
        if 'recommendations' not in analysis:
            analysis['recommendations'] = ['An√°lise completa dispon√≠vel no dashboard']
        
        logger.info(f"‚úÖ An√°lise completa: {len(analysis.get('underperforming_campaigns', []))} campanhas com problemas")
        
        if analysis.get('risk_financeiro', 0) > 100:
            logger.warning(f"üí∞ Risco financeiro: ‚Ç¨{analysis['risk_financeiro']:.2f}")
        
        return analysis
    
    def _generate_alerts(self, analysis: Dict) -> List[Dict]:
        """Gera alertas detalhados - Standard mode"""
        logger.info("üö® Gerando alertas com modelo standard...")
        
        issues = analysis.get('underperforming_campaigns', [])
        risk = analysis.get('risk_financeiro', 0)
        summary = analysis.get('issues_summary', 'Problemas detectados na an√°lise')
        
        if not issues and risk < 50:
            logger.info("‚úÖ Nenhum alerta cr√≠tico necess√°rio")
            return []
        
        prompt = f"""
        Voc√™ √© gerente de tr√°fego s√™nior. Escreva alertas profissionais para o time de marketing.
        
        CONTEXTO:
        - {len(issues)} campanhas com performance abaixo do esperado
        - Risco financeiro: ‚Ç¨{risk:.2f} em spend ineficiente
        - Problemas identificados: {summary[:200]}
        
        CRIE ALERTAS NO FORMATO:
        - N√≠vel: CR√çTICO / ALTO / M√âDIO / BAIXO
        - T√≠tulo: m√°ximo 50 caracteres, direto e impactante
        - Descri√ß√£o: 2-3 frases com contexto e n√∫meros espec√≠ficos
        - A√ß√£o imediata: o que fazer agora (m√°ximo 80 caracteres)
        - Meta: resultado esperado da a√ß√£o
        
        PRIORIDADE:
        1. CR√çTICO: ROAS < 1.5 ou risco > ‚Ç¨200
        2. ALTO: ROAS < 2.5 ou CTR < 0.5%
        3. M√âDIO: ROAS < 3.0 ou CTR < 1.0%
        4. BAIXO: otimiza√ß√µes menores
        
        Retorne APENAS uma lista de objetos JSON:
        [
            {{
                "level": "CR√çTICO|ALTO|M√âDIO|BAIXO",
                "title": "T√≠tulo do alerta",
                "description": "Descri√ß√£o detalhada",
                "action": "A√ß√£o imediata",
                "metric": "m√©trica afetada",
                "current_value": float,
                "target": float,
                "financial_impact": float
            }}
        ]
        
        M√°ximo 3 alertas, seja objetivo e profissional.
        """
        
        response = self.router.call(
            task_type='write_alert',
            messages=[{"role": "user", "content": prompt.strip()}],
            temperature=0.3,
            max_tokens=1000
        )
        
        content = response.choices[0].message.content.strip()
        
        # Parse alertas
        try:
            alerts = json.loads(content)
            if not isinstance(alerts, list):
                alerts = [alerts]
        except json.JSONDecodeError:
            # Fallback: criar alertas gen√©ricos baseados nos dados
            alerts = []
            for issue in issues[:2]:  # M√°ximo 2 alertas
                severity = 'HIGH' if issue.get('current_value', 0) < 2.0 else 'MEDIUM'
                alerts.append({
                    'level': 'CR√çTICO' if severity == 'HIGH' else 'M√âDIO',
                    'title': f"Performance {issue['name']}",
                    'description': f"Campanha {issue['name']} com {issue['issue']}: {issue['current_value']} vs target {issue['target']}",
                    'action': 'Revisar segmenta√ß√£o e criativos',
                    'metric': issue['issue'].lower(),
                    'current_value': issue['current_value'],
                    'target': issue['target'],
                    'financial_impact': issue.get('spend_impact', 0)
                })
        
        # Log alertas
        for alert in alerts:
            emoji = "üö®" if alert['level'] == 'CR√çTICO' else "‚ö†Ô∏è" if alert['level'] == 'ALTO' else "üí°"
            logger.warning(f"{emoji} ALERTA {alert['level']}: {alert['title']}")
        
        return alerts
    
    def _debug_analysis_failure(self, raw_data: Dict) -> Dict:
        """Debug complexo em caso de falha - Deep mode (<1% do uso)"""
        logger.warning("üîß Debug complexo de falha de an√°lise...")
        
        prompt = f"""
        DEBUG DE FALHA EM AN√ÅLISE DE PERFORMANCE
        
        Dados brutos que causaram falha:
        {json.dumps(raw_data, indent=2, default=str)[:1500]}
        
        TENTE:
        1. Identificar por que a an√°lise anterior falhou
        2. Propor corre√ß√µes no formato de dados
        3. Sugerir melhorias no processo de an√°lise
        4. Criar an√°lise alternativa simplificada
        
        RETORNE:
        {{
            "debug_status": "completed",
            "failure_reason": "motivo identificado",
            "suggested_fix": "corre√ß√£o proposta",
            "simple_analysis": {{
                "has_issues": boolean,
                "basic_recommendations": ["rec1", "rec2"]
            }}
        }}
        """
        
        try:
            response = self.router.call(
                task_type='debug_error',
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_tokens=1000
            )
            
            content = response.choices[0].message.content
            
            # Extrair JSON
            import re
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            else:
                return {
                    'debug_status': 'partial',
                    'failure_reason': 'Unable to parse debug response',
                    'simple_analysis': {
                        'has_issues': True,
                        'basic_recommendations': ['Verificar formato dos dados', 'Tentar an√°lise manual']
                    }
                }
                
        except Exception as e:
            logger.error(f"‚ùå Debug tamb√©m falhou: {e}")
            return {
                'debug_status': 'failed',
                'failure_reason': str(e),
                'simple_analysis': {
                    'has_issues': True,
                    'basic_recommendations': ['An√°lise manual necess√°ria']
                }
            }
    
    def _emergency_debug(self, error_message: str) -> Dict:
        """Debug de emerg√™ncia quando tudo falha"""
        logger.error(f"üö® Debug de emerg√™ncia: {error_message}")
        
        return {
            'emergency_analysis': True,
            'error': error_message,
            'recommendations': [
                'Verificar logs completos',
                'Testar conex√£o com APIs',
                'Reiniciar servi√ßo se necess√°rio',
                'An√°lise manual recomendada'
            ],
            'status': 'emergency_mode'
        }
    
    def _get_cost_breakdown(self) -> Dict:
        """Retorna breakdown de custos do modelo"""
        stats = self.router.get_stats()
        return {
            'economy_cost': stats['by_model']['economy']['cost'],
            'standard_cost': stats['by_model']['standard']['cost'],
            'deep_cost': stats['by_model']['deep']['cost'],
            'total_cost': stats['total_cost_usd'],
            'budget_used': stats['daily_spent'],
            'budget_remaining': stats['budget_remaining']
        }
    
    def _record_performance(self, analysis: Dict, alerts: List[Dict]):
        """Registra performance para an√°lise hist√≥rica"""
        record = {
            'timestamp': datetime.now().isoformat(),
            'has_issues': analysis.get('has_issues', False),
            'num_alerts': len(alerts),
            'risk_financeiro': analysis.get('risk_financeiro', 0),
            'baseline_roas': analysis.get('baseline_roas', 0),
            'num_underperforming': len(analysis.get('underperforming_campaigns', []))
        }
        
        self.performance_history.append(record)
        
        # Manter apenas √∫ltimos 100 registros
        if len(self.performance_history) > 100:
            self.performance_history = self.performance_history[-100:]
    
    def get_performance_trends(self) -> Dict:
        """Retorna tend√™ncias de performance hist√≥rica"""
        if not self.performance_history:
            return {'message': 'Sem dados hist√≥ricos'}
        
        recent = self.performance_history[-10:]  # √öltimos 10 ciclos
        
        trends = {
            'total_cycles': len(self.performance_history),
            'recent_avg_issues': sum(p['has_issues'] for p in recent) / len(recent),
            'recent_avg_alerts': sum(p['num_alerts'] for p in recent) / len(recent),
            'recent_avg_risk': sum(p['risk_financeiro'] for p in recent) / len(recent),
            'trend_direction': 'improving' if recent[-1]['num_alerts'] < recent[0]['num_alerts'] else 'worsening'
        }
        
        return trends
    
    def generate_weekly_report(self) -> Dict:
        """Gera relat√≥rio semanal completo"""
        trends = self.get_performance_trends()
        router_stats = self.router.get_stats()
        
        return {
            'period': 'last_7_days',
            'performance_trends': trends,
            'cost_analysis': {
                'total_spent': router_stats['total_cost_usd'],
                'daily_average': router_stats['daily_spent'],
                'budget_utilization': router_stats['budget_utilization']
            },
            'model_distribution': router_stats['distribution'],
            'recommendations': self.router.get_recommendations()
        }